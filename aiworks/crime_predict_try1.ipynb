{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries. Using RandomForestRegressor and KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump, load\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latitude,longitude,crime-severity,male-female-ratio,timestamp\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df['datetime'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "    #temporal features\n",
    "    df['hour'] = df['datetime'].dt.hour\n",
    "    df['day_of_week'] = df['datetime'].dt.dayofweek\n",
    "    df['month'] = df['datetime'].dt.month\n",
    "\n",
    "    #encoding for the above\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour']/24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour']/24)\n",
    "    df['day_sin'] = np.sin(2 * np.pi * df['day_of_week']/7)\n",
    "    df['day_cos'] = np.cos(2 * np.pi * df['day_of_week']/7)\n",
    "\n",
    "    return df.drop(['timestamp','datetime'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating spatial features using Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spatial_features(df, kmeans_model):\n",
    "    coords = df[['latitude', 'longitude']].values\n",
    "    distances = kmeans_model.transform(coords)\n",
    "    df['min_cluster_dist'] = distances.min(axis=1)\n",
    "    \n",
    "    # Get nearest cluster label\n",
    "    df['cluster'] = kmeans_model.predict(coords)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train pipeline with train-test spilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'regressor__max_depth': 10, 'regressor__min_samples_leaf': 1, 'regressor__min_samples_split': 10, 'regressor__n_estimators': 300}\n",
    "def train_model(data_path, n_clusters=10):\n",
    "    # Load and preprocess data\n",
    "    df = pd.read_csv(data_path)\n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    # Spatial clustering\n",
    "    coords = df[['latitude', 'longitude']].values\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    kmeans.fit(coords)\n",
    "\n",
    "    # Calling spatial features\n",
    "    df = create_spatial_features(df, kmeans)\n",
    "\n",
    "    # Calculate cluster crime severity\n",
    "    cluster_severity = df.groupby('cluster')['crime-severity'].mean().to_dict()\n",
    "    df['cluster_severity'] = df['cluster'].map(cluster_severity)\n",
    "    \n",
    "    # Create severity-adjusted ratio\n",
    "    # df['severity_adjusted_ratio'] = df['male-female-ratio'] * df['cluster_severity']\n",
    "    # If the area (cluster) has low crime severity (<3) the male-female ratio is not given weight.\n",
    "    df['severity_adjusted_ratio'] = np.where(\n",
    "        df['cluster_severity'] <= 3,\n",
    "        df['cluster_severity'],\n",
    "        df['male-female-ratio'] * df['cluster_severity']\n",
    "    )\n",
    "    spatial_threshold = df['min_cluster_dist'].quantile(0.95)\n",
    "\n",
    "    # Features aur target\n",
    "    features = ['latitude', 'longitude', 'severity_adjusted_ratio',\n",
    "                'hour_sin', 'hour_cos', 'day_sin', 'day_cos',\n",
    "                'month', 'cluster_severity']\n",
    "    \n",
    "    \n",
    "\n",
    "    # Downsample low-severity samples with high ratios\n",
    "    high_ratio_mask = (df['male-female-ratio'] > 1.2) & (df['crime-severity'] <= 3)\n",
    "    df_filtered = df[~high_ratio_mask]\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df_filtered[features], \n",
    "        df_filtered['crime-severity'],\n",
    "        test_size=0.2, \n",
    "        random_state=42\n",
    "    )\n",
    "    model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', RandomForestRegressor(\n",
    "            n_estimators=300,\n",
    "            random_state=42,\n",
    "            max_depth=10,\n",
    "            min_samples_split=10,\n",
    "            min_samples_leaf=1\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # errors\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "    print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "    \n",
    "    # Save model\n",
    "    artifacts = {\n",
    "        'model': model,\n",
    "        'kmeans': kmeans,\n",
    "        'cluster_severity': cluster_severity,\n",
    "        'spatial_threshold': spatial_threshold,\n",
    "        'features': features\n",
    "    }\n",
    "    dump(artifacts, 'crime_prediction_model.joblib')\n",
    "    \n",
    "    return model, kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.18\n",
      "Mean Squared Error: 2.38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('regressor',\n",
       "                  RandomForestRegressor(max_depth=10, min_samples_split=10,\n",
       "                                        n_estimators=300, random_state=42))]),\n",
       " KMeans(n_clusters=250, random_state=42))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Main\n",
    "train_model('women_crime_data_2.csv',250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_severity(input_data):\n",
    "    # Load model and artifacts\n",
    "    artifacts = load('crime_prediction_model.joblib')\n",
    "    model = artifacts['model']\n",
    "    kmeans = artifacts['kmeans']\n",
    "    cluster_severity = artifacts['cluster_severity']\n",
    "    spatial_threshold = artifacts['spatial_threshold']\n",
    "    features = artifacts['features']\n",
    "\n",
    "    \n",
    "    # Create DataFrame from input\n",
    "    df = pd.DataFrame([input_data])\n",
    "    df = preprocess_data(df)\n",
    "    df = create_spatial_features(df, kmeans)\n",
    "\n",
    "    print(df['min_cluster_dist'].values)  #given here for checking purpose\n",
    "    print(df['cluster'].values) \n",
    "\n",
    "    if df['min_cluster_dist'].iloc[0] > spatial_threshold:\n",
    "        # print(\"Location is far away from training data. Returning 0 severity.\")\n",
    "        return 0.0\n",
    "\n",
    "    # Add cluster-based features\n",
    "    df['cluster_severity'] = df['cluster'].map(cluster_severity)\n",
    "    # df['severity_adjusted_ratio'] = df['male-female-ratio'] * df['cluster_severity']\n",
    "    print(df['cluster_severity'].values)\n",
    "\n",
    "    df['severity_adjusted_ratio'] = np.where(\n",
    "        df['cluster_severity'] <= 3,\n",
    "        df['cluster_severity'],\n",
    "        df['male-female-ratio'] * df['cluster_severity']\n",
    "    )     \n",
    "    \n",
    "    \n",
    "    return model.predict(df[features])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00271141]\n",
      "[55]\n",
      "[4.]\n",
      "Predicted crime severity: 4.93\n"
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "        'latitude': 22.95168,\n",
    "        'longitude': 88.38841,                  #I have chosen low risk area here which is not present in train set\n",
    "        'timestamp': '2025-02-10 08:30:00',\n",
    "        'male-female-ratio': 2.5\n",
    "}\n",
    "    \n",
    "prediction = predict_severity(input_data)\n",
    "print(f\"Predicted crime severity: {prediction:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00382189]\n",
      "[18]\n",
      "[5.]\n",
      "Predicted crime severity: 4.22\n"
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "        'latitude': 22.94821,\n",
    "        'longitude': 88.38052,                  #I have chosen high risk area here which partially matches in train set\n",
    "        'timestamp': '2025-02-04 21:30:00', \n",
    "        'male-female-ratio': 1.5\n",
    "}\n",
    "    \n",
    "prediction = predict_severity(input_data)\n",
    "print(f\"Predicted crime severity: {prediction:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best Hyperparameters: {'regressor__max_depth': 10, 'regressor__min_samples_leaf': 4, 'regressor__min_samples_split': 10, 'regressor__n_estimators': 300}\n",
      "Best Cross-Validation Score (MSE): 3.8575543527755665\n",
      "Test Mean Squared Error: 3.91132992388097\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "df = pd.read_csv('women_crime_data_2.csv')\n",
    "df = preprocess_data(df)\n",
    "\n",
    "# Spatial clustering\n",
    "coords = df[['latitude', 'longitude']].values\n",
    "kmeans = KMeans(n_clusters=100, random_state=42)\n",
    "kmeans.fit(coords)\n",
    "\n",
    "# Calling spatial features\n",
    "df = create_spatial_features(df, kmeans)\n",
    "\n",
    "cluster_severity = df.groupby('cluster')['crime-severity'].mean().to_dict()\n",
    "df['cluster_severity'] = df['cluster'].map(cluster_severity)\n",
    "\n",
    "# Create severity-adjusted ratio\n",
    "# df['severity_adjusted_ratio'] = df['male-female-ratio'] * df['cluster_severity']\n",
    "# If the area (cluster) has low crime severity (<3) the male-female ratio is not given weight.\n",
    "df['severity_adjusted_ratio'] = np.where(\n",
    "    df['cluster_severity'] <= 3,\n",
    "    df['cluster_severity'],\n",
    "    df['male-female-ratio'] * df['cluster_severity']\n",
    ")\n",
    "\n",
    "# Features aur target\n",
    "features = ['latitude', 'longitude', 'severity_adjusted_ratio',\n",
    "                'hour_sin', 'hour_cos', 'day_sin', 'day_cos',\n",
    "                'month', 'cluster_severity']\n",
    "\n",
    "X = df[features]\n",
    "y = df['crime-severity']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', RandomForestRegressor(random_state=42))\n",
    "    ])\n",
    "\n",
    "\n",
    "# hyperparameters test for grid search\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__max_depth': [None, 10, 20, 30],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf_model,\n",
    "                           param_grid=param_grid,\n",
    "                           n_jobs=6,                        # I had 8 cores, hence chosen 6 parallel job\n",
    "                           cv=5,                      \n",
    "                           scoring='neg_mean_squared_error', \n",
    "                           verbose=1)                \n",
    "\n",
    "# Fit grid search to training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve best parameters and score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = -grid_search.best_score_ \n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Cross-Validation Score (MSE):\", best_score)\n",
    "\n",
    "# Evaluate on test set using the best estimator found by grid search\n",
    "y_pred = grid_search.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Test Mean Squared Error:\", test_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
